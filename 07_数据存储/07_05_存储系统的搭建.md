
https://www.yuque.com/fairy-era/yg511q/oxbopw


# 1 存储相关概念

  
- 在容器世界中，无状态是一个核心原则，然而我们始终需要保存数据，并提供给他人进行访问，所以就需要一个方案用于保持数据，以备重启之需。
- 在 Kubernetes 中，PVC 是管理有状态应用的一个推荐方案。有了 PVC 的帮助，Pod 可以申请并连接到存储卷，这些存储卷在 Pod 生命周期结束之后，还能独立存在。
- PVC 在存储方面让开发和运维的职责得以分离。运维人员负责供应存储，而开发人员则可以在不知后端细节的情况下，申请使用这些存储卷。
- PVC 由一系列组件构成：
    - [PVC](https://kubernetes.io/docs/concepts/storage/volumes/#persistentvolumeclaim)：是 Pod 对存储的请求。PVC 会被 Pod 动态加载成为一个存储卷。
    - [PV](https://kubernetes.io/docs/concepts/storage/persistent-volumes/)，可以由运维手工分配，也可以使用 `StorageClass` 动态分配。PV 受 Kubernetes 管理，但并不与特定的 Pod 直接绑定。
    - [StorageClass](https://kubernetes.io/docs/concepts/storage/storage-classes/)：由管理员创建，可以用来动态的创建存储卷和 PV。

- 物理存储：实际连接和加载的存储卷。
- 分布式存储系统是一个有效的解决有状态工作负载高可用问题的方案。Ceph 就是一个分布式存储系统，近年来其影响主键扩大。Rook 是一个编排器，能够支持包括 Ceph 在内的多种存储方案。Rook 简化了 Ceph 在 Kubernetes 集群中的部署过程。
- 在生产环境中使用 Rook + Ceph 组合的用户正在日益增加，尤其是自建数据中心的用户，[CENGNopen in new window](https://www.cengn.ca/)、Gini、GPR 等很多组织都在进行评估。


![1.png](https://cdn.nlark.com/yuque/0/2022/png/513185/1651636041264-c605a686-423c-4751-91b4-a12f82a7f053.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_17%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10%2Fformat%2Cwebp)


# 2 Ceph

- Ceph 可以有如下的功能：
    - Ceph 对象存储：键值存储，其接口就是简单的 GET,PUT,DEL 等。如七牛，阿里云 oss 等。
    - Ceph 块设备：**AWS 的 EBS** ，**青云的云硬盘**和**阿里云的盘古系统**，还有**Ceph的RBD**(RBD 是 Ceph 面向块存储的接口)
    - Ceph 文件系统：它比块存储具有更丰富的接口，需要考虑目录、文件属性等支持，实现一个支持并行化的文件存储应该是最困难的。
- 一个 Ceph 存储集群需要
    - 至少一个 Ceph 监视器、Ceph 管理器、Ceph OSD（对象存储守护程序）
    - 需要运行 Ceph 文件系统客户端，则需要部署 Ceph Metadata Server。

![2.png](https://cdn.nlark.com/yuque/0/2022/png/513185/1651636046947-0bf452b5-05d4-49fb-a70d-8789c86db3fb.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_20%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10%2Fformat%2Cwebp)


- **Monitors**:  [Ceph Monitor](https://docs.ceph.com/en/latest/glossary/#term-Ceph-Monitor) (`ceph-mon`) 监视器：维护集群状态信息
    - 维护集群状态的映射，包括监视器映射，管理器映射，OSD 映射，MDS 映射和 CRUSH 映射。
    - 这些映射是 Ceph 守护程序相互协调所必需的关键群集状态。
    - 监视器还负责管理守护程序和客户端之间的身份验证。
    - 通常至少需要三个监视器（这也是为什么需要三个 Node 节点的原因所在）才能实现冗余和高可用性。

- **Managers**: [Ceph Manager](https://docs.ceph.com/en/latest/glossary/#term-Ceph-Manager) 守护进程(`ceph-mgr`) : 负责跟踪运行时指标和 Ceph 集群的当前状态
    - Ceph Manager 守护进程（ceph-mgr）负责跟踪运行时指标和 Ceph 集群的当前状态
    - 包括存储利用率，当前性能指标和系统负载。
    - Ceph Manager 守护程序还托管基于 python 的模块，以管理和公开 Ceph 集群信息，包括基于 Web 的 Ceph Dashboard 和REST API 。
    - 通常，至少需要两个管理器才能实现高可用性。

- **Ceph OSDs**: [Ceph OSD](https://docs.ceph.com/en/latest/glossary/#term-Ceph-OSD) (对象存储守护进程, `ceph-osd`) 【存储数据】
    - 通过检查其他 Ceph OSD 守护程序的心跳来存储数据，处理数据复制，恢复，重新平衡，并向 Ceph 监视器和管理器提供一些监视信息。
    - 通常至少需要 3 个 Ceph OSD 才能实现冗余和高可用性。

- **MDSs**: [Ceph Metadata Server](https://docs.ceph.com/en/latest/glossary/#term-Ceph-Metadata-Server) (MDS, `ceph-mds`ceph 元数据服务器)
    - 存储能代表 [Ceph File System](https://docs.ceph.com/en/latest/glossary/#term-Ceph-File-System) 的元数据(如：Ceph 块设备和 Ceph 对象存储不使用 MDS)。
    - Ceph 元数据服务器允许 POSIX 文件系统用户执行基本命令（如 ls，find 等），而不会给 Ceph 存储集群带来巨大负担。


# 3 第三章 Rook


## 3.1 基本概念


Rook 是云原生平台的存储编排工具。


Rook 工作原理如下：

![3.png](https://cdn.nlark.com/yuque/0/2022/png/513185/1651636052140-916f1ffe-0bda-4506-a979-356a40eedd89.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_33%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10%2Fformat%2Cwebp)



Rook 的架构图如下

![4.png](https://cdn.nlark.com/yuque/0/2022/png/513185/1651636057354-738f8251-5ff0-493b-8558-ae61d550853c.png?x-oss-process=image%2Fwatermark%2Ctype_d3F5LW1pY3JvaGVp%2Csize_66%2Ctext_6K645aSn5LuZ%2Ccolor_FFFFFF%2Cshadow_50%2Ct_80%2Cg_se%2Cx_10%2Cy_10%2Fformat%2Cwebp%2Fresize%2Cw_773%2Climit_0)




## 3.2 Operator 是什么？

- k8s 中 Operator + CRD（CustomResourceDefinitions【k8s自定义资源类型】），可以快速帮我们部署一些有状态应用集群，如redis，mysql，Zookeeper 等。
- Rook 的 Operator 是 k8s 集群和存储集群之间进行交互的解析器。


# 4 部署

https://www.yuque.com/fairy-era/yg511q/oxbopw


