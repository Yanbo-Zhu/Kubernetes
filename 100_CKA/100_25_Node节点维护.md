
# 1 题目

![](image/2cka20240429174539%201.png)

配置环境kubectl config use-context ek8s

将名为ek8s-node-01 或者 node01 的node节点设置为不可用，并重新调度该node上所有运行的pods。
将名为 node02 的 node 设置为不可用，并重新调度该 node 上所有运行的 pods。


# 2 参考
https://kubernetes.io/zh/docs/tasks/configure-pod-container/
https://kubernetes.io/zh-cn/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/
https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#drain
https://kubernetes.io/zh-cn/docs/tasks/administer-cluster/safely-drain-node/

https://kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/#use-kubectl-drain-to-remove-a-node-from-service

1 Get Pods on Specific Nodes
`kubectl get pods --all-namespaces -o wide --field-selector spec.nodeName=<node>`

# 3 解答

1、切换答题环境（考试环境有多个，每道题要在对应的环境中作答）
kubectl config use-context ek8s


2、设置节点不可调度

kubectl cordon ek8s-node-0
说明：将节点不可调度后，表示节点上无法再部署pod。

cordon: 用警戒线围住；包围隔离


3、驱除k8s-node-1节点上Pod

最好一步到位 执行这个 
kubectl drain ek8s-node-1 --ignore-daemonsets --delete-emptydir-data --force --dry-run=server


```sh
kubectl drain ek8s-node-0 --ignore-daemonsets

会得到message
node/node01 already cordoned
error: unable to drain node "node01" due to error:[cannot delete cannot delete Pods that declare no controller (use --force to override): default/11-factor-app, default/foo, default/my-csi-app, cannot delete Pods with local storage (use --delete-emptydir-data to override): kube-system/metrics-server-85bc58ccff-ggb5q], continuing command...
There are pending nodes to be drained:
 node01
cannot delete cannot delete Pods that declare no controller (use --force to override): default/11-factor-app, default/foo, default/my-csi-app
cannot delete Pods with local storage (use --delete-emptydir-data to override): kube-system/metrics-server-85bc58ccff-ggb5q

```


```sh
kubectl drain ek8s-node-0 --ignore-daemonsets

# 注意，还有一个参数--delete-emptydir-data --force，这个考试时不用加，就可以正常 draini node02 的。
# 但如果执行后，有跟测试环境一样的报错，则需要加上--delete-emptydir-data --force，会强制将 pod 移除。
kubectl drain ek8s-node-0 --ignore-daemonsets --delete-emptydir-data --force

# 测试执行
kubectl drain ek8s-node-1 --ignore-daemonsets --delete-emptydir-data --force --dry-run=server
```


dry-run
Must be "none", "server", or "client". If client strategy, only print the object that would be sent, without sending it. If server strategy, submit server-side request without persisting the resource. 

4、检查操作内容
kubectl get nodes

